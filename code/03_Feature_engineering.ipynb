{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267f8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b674808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/final_work_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991b99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d0bb7",
   "metadata": {},
   "source": [
    "### Identification of the interaction columns worth including into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the interactions that are worth analyzing excluding the unrelated string columns\n",
    "test = []\n",
    "train = []\n",
    "cross = []\n",
    "\n",
    "#looping through correlations limits\n",
    "for z in [-1, -.95, -.9, -.85, -.8, -.75, -.7, -.65, -.6, -.55, -.5, -.45, -.4, -.35, -.3, -.25, -.2, -.15, -.1, -.05]:\n",
    "    for v in [1, .95, .9, .85, .8, .75, .7, .65, .6, .55, .5, .45, .4, .35, .3, .25, .2, .15, .1, .05]:\n",
    "        interaction = []\n",
    "        df1 = df.copy()\n",
    "        df1 = df1.drop(columns=['state', 'county_name', 'unemployment_rate_2010', 'population_total_2010'])\n",
    "        for i in list(df1.corr().columns):\n",
    "            for j in list(df1.corr().index):\n",
    "                if ((df1.corr().loc[j, i] < z  and df1.corr().loc[j, i] != -1) or (df1.corr().loc[j, i] > v and df1.corr().loc[j, i] != 1)) and j != i:\n",
    "                        interaction.append((j, i))\n",
    "\n",
    "        # creating the columns with identified interactions\n",
    "        for a in interaction:\n",
    "            df1[a[0]+'_'+a[1]] = df1[a[0]] * df1[a[1]]\n",
    "\n",
    "        #saving the dataframe to feed into the model\n",
    "        #df.to_csv('../data/final_preprocessed_data_with_polynomials.csv')\n",
    "\n",
    "        X = df1#.drop(columns = ['state', 'county_name', 'unemployment_rate_2010', 'population_total_2010'])\n",
    "        y = df['unemployment_rate_2010']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        Z_train = ss.fit_transform(X_train)\n",
    "        Z_test = ss.transform(X_test)\n",
    "\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(Z_train, y_train)\n",
    "        if not lr.score(Z_test, y_test) < 0 and not cross_val_score(lr, Z_train, y_train).mean() < 0:\n",
    "            test.append((z, v, lr.score(Z_train, y_train)))\n",
    "            train.append((z, v, lr.score(Z_test, y_test)))\n",
    "            cross.append((z, v, cross_val_score(lr, Z_train, y_train).mean()))\n",
    "        print('z:' + str(z) + '; v:' + str(v) + \"; train: \" + str(lr.score(Z_train, y_train)) + \"; test: \" + str(lr.score(Z_test, y_test)) + \"; cross: \" + str(cross_val_score(lr, Z_train, y_train).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a146b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the maximum train score and its correlation cutoffs\n",
    "maximum =-999\n",
    "\n",
    "for num in train:\n",
    "    if num[2] > maximum:\n",
    "        maximum=num[2]\n",
    "maximum\n",
    "for num in train:\n",
    "    if num[2]==maximum:\n",
    "        print(\"train: \" + str(num))\n",
    "        for klm in test:\n",
    "            if klm[0] == num[0] and klm[1] == num[1]:\n",
    "                print(\"test: \" + str(klm))\n",
    "        for mmm in cross:\n",
    "            if mmm[0] == num[0] and mmm[1] == num[1]:\n",
    "                print(\"cross: \" + str(mmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the maximum test score and its correlation cutoffs\n",
    "maximum2 =-999\n",
    "\n",
    "for num2 in test:\n",
    "    if num2[2] > maximum2:\n",
    "        maximum2=num2[2]\n",
    "maximum2\n",
    "for num2 in test:\n",
    "    if num2[2]==maximum2:\n",
    "        print(\"test: \" + str(num2))\n",
    "        for klm in train:\n",
    "            if klm[0] == num2[0] and klm[1] == num2[1]:\n",
    "                print(\"train: \" + str(klm))\n",
    "        for mmm in cross:\n",
    "            if mmm[0] == num2[0] and mmm[1] == num2[1]:\n",
    "                print(\"cross: \" + str(mmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the maximum cross_val_score and its correlation cutoffs\n",
    "maximum3 =-999\n",
    "\n",
    "for num3 in cross:\n",
    "    if num3[2] > maximum3:\n",
    "        maximum3=num3[2]\n",
    "maximum3\n",
    "for num3 in cross:\n",
    "    if num3[2]==maximum3:\n",
    "        print(\"cross: \" + str(num3))\n",
    "        for klm in train:\n",
    "            if klm[0] == num3[0] and klm[1] == num3[1]:\n",
    "                print(\"train: \" + str(klm))\n",
    "        for mmm in test:\n",
    "            if mmm[0] == num3[0] and mmm[1] == num3[1]:\n",
    "                print(\"test: \" + str(mmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8646aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the scores\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(test)):\n",
    "    plt.scatter(i, train[i][2], color='blue')\n",
    "    plt.scatter(i, test[i][2], color='green')\n",
    "    plt.scatter(i, cross[i][2], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c877e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the index with the maximum sum of train, test and cross_val scores\n",
    "maxim = -999\n",
    "for i in range(len(test)):\n",
    "    if (test[i][2] + train[i][2] + cross[i][2]) > maxim:\n",
    "        maxim=(test[i][2] + train[i][2] + cross[i][2])\n",
    "for i in range(len(test)):\n",
    "    if (test[i][2] + train[i][2] + cross[i][2]) == maxim:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[195], test[195], cross[195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec529bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df1#.drop(columns = ['state', 'county_name', 'unemployment_rate_2010', 'population_total_2010'])\n",
    "#y = df['unemployment_rate_2010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#residuals = preds - y.mean()\n",
    "#plt.hist(residuals, bins=200);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
